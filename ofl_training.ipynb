{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38cbd77-32fe-4c7b-b78b-479a8b334674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import duckdb\n",
    "import requests\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from geopy.geocoders import Nominatim\n",
    "import altair as alt\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import ee\n",
    "import time, requests\n",
    "import os\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ffb52a-38ed-4c6f-af27-c8bfa7dd6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='ee-shaddie77')\n",
    "\n",
    "CENSUS_API_KEY = st.secrets.get(\"CENSUS_API_KEY\", \"\")  # set via Streamlit secrets or replace string\n",
    "HUGGINGFACE_DATASET = \"foursquare/fsq-os-places\"\n",
    "HF_PARQUET_API = f\"https://datasets-server.huggingface.co/parquet?dataset={HUGGINGFACE_DATASET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df53485-1b50-4b03-b411-171123fb9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# PARAMETERS\n",
    "# ------------------------\n",
    "radius_m = 100       # Neighborhood radius\n",
    "cr = 50              # Subcircle radius\n",
    "radius_c = 50        # Candidate facility radius (for city split)\n",
    "city_name = \"New York, NY\"\n",
    "\n",
    "\n",
    "# --- Parameters\n",
    "location_name = \"Times Square, New York, NY\"\n",
    "# location_name = \"New York, NY\"\n",
    "# --- Geocode location\n",
    "lat, lon = ox.geocoder.geocode(city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00d1fc8-34da-46cd-bdf0-8c16a0afaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_city_candidate_locations(location_name, radius_c):\n",
    "    # Use OSMnx to get city polygon\n",
    "    print(f'Generating candidate locations ...')\n",
    "    gdf = ox.geocode_to_gdf(location_name)\n",
    "    city_poly = gdf.geometry.iloc[0]\n",
    "    bounds = city_poly.bounds\n",
    "\n",
    "    step = radius_c * 1.5\n",
    "    deg_step = step / 111_320\n",
    "    print(f'size of generate city loop: {len(np.arange(bounds[1], bounds[3], deg_step))}')\n",
    "    candidates = []\n",
    "    count = 0\n",
    "    for lat in np.arange(bounds[1], bounds[3], deg_step):\n",
    "        for lon in np.arange(bounds[0], bounds[2], deg_step):\n",
    "            p = Point(lon, lat)\n",
    "            if city_poly.contains(p):\n",
    "                candidates.append((lat, lon))\n",
    "        # print(f'current count of generate city loop: {count}')\n",
    "        count += 1\n",
    "    return candidates[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95d9800-01d3-48ee-abc5-e1d0f284b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for median income retrieval\n",
    "def get_median_income_by_point(lat, lon, radius):\n",
    "    # TODO: Replace with buffered multi-tract ACS query\n",
    "    print(f'Getting media_income ...')\n",
    "    \"\"\"Use FCC API to find block FIPS then Census ACS to fetch B19013_001E (median household income).\"\"\"\n",
    "    if not CENSUS_API_KEY:\n",
    "        raise RuntimeError(\"CENSUS_API_KEY is not set. Put your key in Streamlit secrets or set variable.\")\n",
    "    # FCC to get block FIPS\n",
    "    j = get_fips_from_coords(lat, lon, retries=3, wait=5)\n",
    "    block_fips = j.get(\"Block\", {}).get(\"FIPS\")\n",
    "    if not block_fips:\n",
    "        return None\n",
    "    state_fips = block_fips[0:2]\n",
    "    county_fips = block_fips[2:5]\n",
    "    tract_fips = block_fips[5:11]\n",
    "\n",
    "    headers = {\n",
    "        \"X-API-Key\": CENSUS_API_KEY\n",
    "    }\n",
    "\n",
    "    acs_url = (\n",
    "        \"https://api.census.gov/data/2022/acs/acs5\"\n",
    "        f\"?get=B19013_001E&for=tract:{tract_fips}&in=state:{state_fips}%20county:{county_fips}&key={CENSUS_API_KEY}\"\n",
    "    )\n",
    "    r2 = requests.get(acs_url, headers=headers, timeout=50)\n",
    "    r2.raise_for_status()\n",
    "    arr = r2.json()\n",
    "    if len(arr) < 2:\n",
    "        return None\n",
    "    val = arr[1][0]\n",
    "    try:\n",
    "        return float(val) if val not in (None, \"\", \"null\") else None\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf9d66e-45fe-4e3e-9b20-ecb9a79a50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating candidate locations ...\n",
      "size of generate city loop: 655\n",
      "size of candidates 99\n",
      "element of candidates (40.477251733381244, -74.22717753108134)\n"
     ]
    }
   ],
   "source": [
    "candidates = generate_city_candidate_locations(city_name, radius_c)\n",
    "print(f'size of candidates {len(candidates)}')\n",
    "print(f'element of candidates {candidates[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f3e3d9-d882-4b67-be64-d794c45784d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_points(center_lat, center_lon, big_radius, N=10):\n",
    "    \"\"\"\n",
    "    Generates subcircle centers within big circle.\n",
    "    small_radius is chosen so that the number of subcircles <= N.\n",
    "    \"\"\"\n",
    "    print(f'Generating circle points with max {N} subcircles')\n",
    "\n",
    "    def count_points_for_radius(small_radius):\n",
    "        step = small_radius * 1.5\n",
    "        deg_step = step / 111_320\n",
    "        count = 0\n",
    "        for lat in np.arange(center_lat - big_radius/111_320,\n",
    "                             center_lat + big_radius/111_320, deg_step):\n",
    "            for lon in np.arange(center_lon - big_radius/111_320,\n",
    "                                 center_lon + big_radius/111_320, deg_step):\n",
    "                if haversine(center_lon, center_lat, lon, lat) <= big_radius:\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "    # Binary search for the largest small_radius that satisfies count <= N\n",
    "    low, high = 1.0, big_radius  # meters\n",
    "    best_radius = low\n",
    "    for _ in range(30):  # enough iterations for sub-meter precision\n",
    "        mid = (low + high) / 2\n",
    "        if count_points_for_radius(mid) <= N:\n",
    "            best_radius = mid\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "    low = 50\n",
    "    best_radius = 50\n",
    "    print(f'low, high {low}, {high}')\n",
    "\n",
    "    # Now generate the actual points with the chosen radius\n",
    "    step = best_radius * 1.5\n",
    "    deg_step = step / 111_320\n",
    "    points = []\n",
    "    print(f'looper {len(np.arange(center_lat - big_radius/111_320, center_lat + big_radius/111_320, deg_step) )}')\n",
    "    for lat in np.arange(center_lat - big_radius/111_320,\n",
    "                         center_lat + big_radius/111_320, deg_step):\n",
    "        print(f'looper 2 {len(np.arange(center_lon - big_radius/111_320, center_lon + big_radius/111_320, deg_step))}')\n",
    "        for lon in np.arange(center_lon - big_radius/111_320,\n",
    "                             center_lon + big_radius/111_320, deg_step):\n",
    "            # print(f'haversine condition {haversine(center_lat, center_lon, lat, lon)} {big_radius}')\n",
    "            if haversine(center_lat, center_lon, lat, lon) <= big_radius:\n",
    "                print(f'haversine condition {haversine(center_lat, center_lon, lat, lon)} {big_radius}')\n",
    "                points.append((lat, lon))\n",
    "\n",
    "    print(f\"Chosen small_radius: {best_radius:.2f} m, generated {len(points)} subcircles\")\n",
    "    return points[0:99] # , best_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368a40f5-7217-4b63-a50a-0b78ab13c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Distance in meters\n",
    "    # print(f'Computing haversine ...')\n",
    "    R = 6371000\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon, dlat = lon2 - lon1, lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    return R * 2 * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605558d1-7aa5-4479-ae10-f360003a47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_osm_poi_density(lat, lon, radius):\n",
    "#     print(f'Getting poi density')\n",
    "#     tags = {\"amenity\": True}\n",
    "#     pois = ox.features_from_point((lat, lon), tags=tags, dist=radius)\n",
    "#     return len(pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d09b8a-20fa-4d67-86e7-46e9bad9b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import osmnx as ox\n",
    "# from osmnx._errors import InsufficientResponseError\n",
    "\n",
    "# def get_osm_poi_density(lat, lon, radius, max_expand=5, expand_factor=2):\n",
    "#     \"\"\"\n",
    "#     Get POI density around (lat, lon). If none are found, expand the radius\n",
    "#     up to max_expand times until results are found.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     lat, lon : float\n",
    "#         Center point coordinates\n",
    "#     radius : float\n",
    "#         Search radius in meters\n",
    "#     max_expand : int\n",
    "#         Number of times to expand search if no results\n",
    "#     expand_factor : float\n",
    "#         Factor by which to expand the radius each retry\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     int : count of POIs\n",
    "#     \"\"\"\n",
    "#     print(f\"Getting POI density at ({lat}, {lon}), radius={radius}m\")\n",
    "\n",
    "#     tags = {\"amenity\": True}\n",
    "#     attempt_radius = radius\n",
    "\n",
    "#     for attempt in range(max_expand + 1):\n",
    "#         try:\n",
    "#             pois = ox.features_from_point((lat, lon), tags=tags, dist=attempt_radius)\n",
    "#             if pois is not None and len(pois) > 0:\n",
    "#                 return len(pois)\n",
    "#             else:\n",
    "#                 print(f\"No POIs found at radius {attempt_radius}m, expanding search...\")\n",
    "#         except InsufficientResponseError:\n",
    "#             print(f\"OSM insufficient response at radius {attempt_radius}m, expanding search...\")\n",
    "\n",
    "#         # Expand radius and retry\n",
    "#         attempt_radius *= expand_factor\n",
    "\n",
    "#     # If nothing found after all expansions\n",
    "#     print(f\"No POIs found after expanding search up to {attempt_radius}m.\")\n",
    "#     return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f855d52e-9894-41bc-8f31-7a8be07b697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_population_density_gee(lat, lon, radius_m):\n",
    "\n",
    "#     print(f'Getting population density gee')\n",
    "#     dataset = ee.ImageCollection(\"WorldPop/GP/100m/pop\") \\\n",
    "#         .filter(ee.Filter.date('2020-01-01', '2020-12-31')) \\\n",
    "#         .first()\n",
    "#     point = ee.Geometry.Point(lon, lat)\n",
    "#     region = point.buffer(radius_m).bounds()\n",
    "#     stats = dataset.reduceRegion(\n",
    "#         reducer=ee.Reducer.mean(),\n",
    "#         geometry=region,\n",
    "#         scale=100,\n",
    "#         maxPixels=1e9\n",
    "#     )\n",
    "#     ans = stats.getInfo().get('population', 0)\n",
    "#     return 0 if ans == None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0cbd3c-f28b-4979-b499-24275fe6932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fsq_count(lat, lon, r):\n",
    "    print(f'Getting Four Square Count')\n",
    "    api_url = \"https://datasets-server.huggingface.co/parquet?dataset=foursquare/fsq-os-places\"\n",
    "    j = requests.get(api_url).json()\n",
    "    parquet_urls = [f['url'] for f in j.get('parquet_files', []) if f['split'] == 'train']\n",
    "    if not parquet_urls:\n",
    "        return 0\n",
    "    url = parquet_urls[0]\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"INSTALL httpfs;\")\n",
    "    con.execute(\"LOAD httpfs;\")\n",
    "\n",
    "    deg = r / 111_320\n",
    "    min_lat, max_lat = lat - deg, lat + deg\n",
    "    min_lon, max_lon = lon - deg, lon + deg\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM '{url}'\n",
    "    WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "      AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "    \"\"\"\n",
    "    res = con.execute(query).df()\n",
    "    return int(res['count'][0]) if res.shape[0] else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8b6702-5630-4001-bca9-9c6f919e3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import ee\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# ee.Initialize()\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: get nearest town/city center\n",
    "# ----------------------------\n",
    "def get_nearest_place_coords(lat, lon):\n",
    "    \"\"\"\n",
    "    Returns (lat, lon) of nearest city/town/village center to the input coordinates.\n",
    "    Uses Nominatim reverse + forward geocoding.\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"geo-fallback-app\")\n",
    "\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True)\n",
    "        if location and \"address\" in location.raw:\n",
    "            addr = location.raw[\"address\"]\n",
    "            place = addr.get(\"city\") or addr.get(\"town\") or addr.get(\"village\")\n",
    "            if place:\n",
    "                place_loc = geolocator.geocode(place)\n",
    "                if place_loc:\n",
    "                    return (place_loc.latitude, place_loc.longitude)\n",
    "    except Exception as e:\n",
    "        print(f\"Geocoding fallback failed: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# POI Density (with fallback)\n",
    "# ----------------------------\n",
    "def get_osm_poi_density(lat, lon, radius, max_expand=3, expand_factor=2):\n",
    "    \"\"\"\n",
    "    Get POI density from OSM.\n",
    "    Expands radius if no POIs found, and falls back to nearest\n",
    "    town/city center if still empty.\n",
    "    \"\"\"\n",
    "    print(f\"Getting POI density at ({lat}, {lon}), radius={radius}m\")\n",
    "\n",
    "    attempt_radius = radius\n",
    "    tags = {\"amenity\": True}\n",
    "\n",
    "    # Try with expanding radius\n",
    "    for attempt in range(max_expand + 1):\n",
    "        try:\n",
    "            pois = ox.features_from_point((lat, lon), tags=tags, dist=attempt_radius)\n",
    "            if len(pois) > 0:\n",
    "                print(f'Found osm_pois {len(pois)}')\n",
    "                return len(pois)\n",
    "            else:\n",
    "                print(f\"No POIs at radius {attempt_radius}m, expanding search...\")\n",
    "        except Exception as e:\n",
    "            print(f\"OSM query failed at radius {attempt_radius}m: {e}\")\n",
    "\n",
    "        attempt_radius *= expand_factor\n",
    "\n",
    "    # Fallback to nearest city/town\n",
    "    print(\"No POIs found after expansions. Falling back to nearest town/city center...\")\n",
    "    fallback_coords = get_nearest_place_coords(lat, lon)\n",
    "    if fallback_coords:\n",
    "        try:\n",
    "            pois = ox.features_from_point(fallback_coords, tags=tags, dist=radius)\n",
    "            if len(pois) > 0:\n",
    "                print(f'Found osm poi {len(pois)}')\n",
    "                return len(pois)\n",
    "        except Exception as e:\n",
    "            print(f\"OSM fallback query failed: {e}\")\n",
    "\n",
    "    print(\"No POIs found, even after fallback.\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Population Density (with fallback)\n",
    "# ----------------------------\n",
    "def get_population_density_gee(lat, lon, radius_m, max_expand=3, expand_factor=2):\n",
    "    \"\"\"\n",
    "    Get population density from WorldPop using Earth Engine.\n",
    "    Expands radius if no values are found, and falls back to nearest\n",
    "    city/town center if still empty.\n",
    "    \"\"\"\n",
    "    print(f\"Getting population density at ({lat}, {lon}), radius={radius_m}m\")\n",
    "\n",
    "    dataset = ee.ImageCollection(\"WorldPop/GP/100m/pop\") \\\n",
    "        .filter(ee.Filter.date('2020-01-01', '2020-12-31')) \\\n",
    "        .first()\n",
    "\n",
    "    attempt_radius = radius_m\n",
    "\n",
    "    # Try with expanding radius\n",
    "    for attempt in range(max_expand + 1):\n",
    "        try:\n",
    "            point = ee.Geometry.Point(lon, lat)\n",
    "            region = point.buffer(attempt_radius).bounds()\n",
    "            stats = dataset.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=region,\n",
    "                scale=100,\n",
    "                maxPixels=1e9\n",
    "            )\n",
    "            result = stats.getInfo()\n",
    "            pop_val = result.get('population', None)\n",
    "            if pop_val is not None:\n",
    "                print(f'Found pop_val {pop_val}')\n",
    "                return pop_val\n",
    "            else:\n",
    "                print(f\"No population data at radius {attempt_radius}m, expanding search...\")\n",
    "        except Exception as e:\n",
    "            print(f\"GEE query failed at radius {attempt_radius}m: {e}\")\n",
    "\n",
    "        attempt_radius *= expand_factor\n",
    "\n",
    "    # Fallback to nearest city/town\n",
    "    print(\"No population found after expansions. Falling back to nearest town/city center...\")\n",
    "    fallback_coords = get_nearest_place_coords(lat, lon)\n",
    "    if fallback_coords:\n",
    "        try:\n",
    "            point = ee.Geometry.Point(fallback_coords[::-1])  # (lon, lat)\n",
    "            region = point.buffer(radius_m).bounds()\n",
    "            stats = dataset.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=region,\n",
    "                scale=100,\n",
    "                maxPixels=1e9\n",
    "            )\n",
    "            result = stats.getInfo()\n",
    "            pop_val = result.get('population', None)\n",
    "            if pop_val is not None:\n",
    "                print(f'Found pop_val {pop_val}')\n",
    "                return pop_val\n",
    "        except Exception as e:\n",
    "            print(f\"GEE fallback query failed: {e}\")\n",
    "\n",
    "    print(\"No population data found, even after fallback.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2be52e-4397-498b-8f2d-4f08bb2a5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_with_fallback(lat, lon, fetch_fn, radii=[200, 500, 1000, 2000], delay=1):\n",
    "    \"\"\"\n",
    "    Try to fetch category with expanding radius. \n",
    "    If still empty, snap to nearest town and retry once.\n",
    "\n",
    "    fetch_fn: function(lat, lon, radius) -> str | None\n",
    "    \"\"\"\n",
    "    for r in radii:\n",
    "        try:\n",
    "            category = fetch_fn(lat, lon, r)\n",
    "            if category:  # got something\n",
    "                return category\n",
    "        except Exception as e:\n",
    "            print(f\"Fetch attempt failed at radius {r}: {e}\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    # Snap to nearest town & retry once\n",
    "    town_lat, town_lon = snap_to_nearest_town(lat, lon)\n",
    "    if (town_lat, town_lon) != (lat, lon):\n",
    "        return category_with_fallback(town_lat, town_lon, fetch_fn, radii, delay)\n",
    "\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b067c8fc-c704-48a7-bf26-fb7feae4f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geo_fallback\")\n",
    "\n",
    "def snap_to_nearest_town(lat, lon):\n",
    "    \"\"\"\n",
    "    Snap (lat, lon) to nearest town/city center if available.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True, language=\"en\")\n",
    "        if location and \"town\" in location.raw[\"address\"]:\n",
    "            town = location.raw[\"address\"][\"town\"]\n",
    "        elif location and \"city\" in location.raw[\"address\"]:\n",
    "            town = location.raw[\"address\"][\"city\"]\n",
    "        else:\n",
    "            return lat, lon  # no town/city info, return same coords\n",
    "\n",
    "        # Forward geocode the town name → town center coords\n",
    "        town_loc = geolocator.geocode(town)\n",
    "        if town_loc:\n",
    "            return town_loc.latitude, town_loc.longitude\n",
    "    except Exception as e:\n",
    "        print(f\"Town fallback failed: {e}\")\n",
    "    return lat, lon  # fallback to original point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5ac8ad-5eb4-4839-bba3-8ea3209b173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def _fetch_foursquare_category(lat, lon, radius):\n",
    "    \"\"\"\n",
    "    Retrieve nearest Foursquare category using Hugging Face fsq-os-places parquet via DuckDB.\n",
    "    Uses fsq_category_labels array (human-readable categories).\n",
    "    \"\"\"\n",
    "    # 1. Get Parquet URL from Hugging Face\n",
    "    api_url = \"https://datasets-server.huggingface.co/parquet?dataset=foursquare/fsq-os-places\"\n",
    "    j = requests.get(api_url).json()\n",
    "    parquet_urls = [f['url'] for f in j.get('parquet_files', []) if f['split'] == 'train']\n",
    "    if not parquet_urls:\n",
    "        raise RuntimeError(\"No parquet file found for fsq-os-places dataset\")\n",
    "    purl = parquet_urls[0]\n",
    "\n",
    "    # 2. DuckDB connection with HTTP + Spatial extensions\n",
    "    con = duckdb.connect(database=':memory:')\n",
    "    con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "    con.execute(\"INSTALL spatial; LOAD spatial;\")  # ✅ spatial extension\n",
    "\n",
    "    con.execute(f\"CREATE TABLE fsq AS SELECT * FROM read_parquet('{purl}')\")\n",
    "\n",
    "    # 3. Query nearest category using spatial distance\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        fsq_category_labels[1] AS cat_label,\n",
    "        ST_Distance(\n",
    "            ST_Point(longitude, latitude),\n",
    "            ST_Point({lon}, {lat})\n",
    "        ) * 111320 AS dist_m\n",
    "    FROM fsq\n",
    "    WHERE ABS(latitude - {lat}) < 0.1 AND ABS(longitude - {lon}) < 0.1\n",
    "      AND fsq_category_labels IS NOT NULL\n",
    "    ORDER BY dist_m\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = con.execute(query).df()\n",
    "        if not df.empty and df.loc[0, \"dist_m\"] <= radius:\n",
    "            return df.loc[0, \"cat_label\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying DuckDB for Foursquare category: {e}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a407229-bb45-4086-820c-d787766df1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foursquare_category(lat, lon):\n",
    "    return category_with_fallback(lat, lon, _fetch_foursquare_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c1155a9-86d3-43d0-9cd3-68a82472e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_osm_category(lat, lon, radius):\n",
    "    tags = {\"amenity\": True, \"shop\": True, \"landuse\": True}\n",
    "    pois = ox.features_from_point((lat, lon), tags=tags, dist=radius)\n",
    "    if len(pois) > 0:\n",
    "        for key in [\"amenity\", \"shop\", \"landuse\"]:\n",
    "            if key in pois.columns:\n",
    "                values = pois[key].dropna().unique()\n",
    "                if len(values) > 0:\n",
    "                    return values[0]\n",
    "    return None\n",
    "\n",
    "def get_osm_category(lat, lon):\n",
    "    return category_with_fallback(lat, lon, _fetch_osm_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "151f189d-ff42-45cc-aee8-ebbd7e822816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_for_location(lat, lon, radius_m, cr):\n",
    "    print(f'Building features for location ...')\n",
    "    neighborhood_points = generate_circle_points(lat, lon, radius_m, cr)\n",
    "    print(f'Number of neighborhood points {len(neighborhood_points)}')\n",
    "    features = []\n",
    "    for (lat_i, lon_i) in neighborhood_points:\n",
    "        pop = get_population_density_gee(lat_i, lon_i, cr)\n",
    "        osm_poi = get_osm_poi_density(lat_i, lon_i, cr)\n",
    "        fsq_poi = get_fsq_count(lat_i, lon_i, cr)\n",
    "        # print(f'pop, fsq_poi {pop} {fsq_poi}')\n",
    "        income = get_median_income_by_point(lat_i, lon_i, cr)\n",
    "        osm_cat = get_osm_category(lat, lon)\n",
    "        fsq_cat = get_foursquare_category(lat, lon)\n",
    "        print(f'Category osm: {osm_cat}, fsq: {fsq_cat}')\n",
    "        # income = get_median_income_with_radius(lat, lon)\n",
    "        features.append({\n",
    "            \"lat\": lat_i,\n",
    "            \"lon\": lon_i,\n",
    "            \"population_density\": pop,\n",
    "            \"osm_poi_density\": osm_poi,\n",
    "            \"fsq_poi_count\": fsq_poi,\n",
    "            \"median_income\": income,\n",
    "            \"location_category_foursquare\": get_foursquare_category(lat, lon),\n",
    "            \"location_category_osm\": get_osm_category(lat, lon),\n",
    "        })\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b5a96c-e59e-417d-85bb-f240a107fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# shared encoders so model always uses the same mapping\n",
    "_fsq_encoder = LabelEncoder()\n",
    "_osm_encoder = LabelEncoder()\n",
    "_encoders_fitted = False\n",
    "\n",
    "def encode_location_categories(df):\n",
    "    \"\"\"\n",
    "    Encode Foursquare + OSM category labels into numeric values\n",
    "    so they can be used as regression features.\n",
    "    \n",
    "    Expects df with columns:\n",
    "        - location_category_foursquare\n",
    "        - location_category_osm\n",
    "    Returns the same df with numeric-encoded columns added.\n",
    "    \"\"\"\n",
    "    global _encoders_fitted\n",
    "\n",
    "    # Ensure columns exist, replace None with \"unknown\"\n",
    "    for col in [\"location_category_foursquare\", \"location_category_osm\"]:\n",
    "        if col not in df:\n",
    "            df[col] = \"unknown\"\n",
    "        df[col] = df[col].fillna(\"unknown\")\n",
    "\n",
    "    # Fit encoders once on all available categories\n",
    "    if not _encoders_fitted:\n",
    "        _fsq_encoder.fit(df[\"location_category_foursquare\"].unique())\n",
    "        _osm_encoder.fit(df[\"location_category_osm\"].unique())\n",
    "        _encoders_fitted = True\n",
    "\n",
    "    # Transform into numeric codes\n",
    "    df[\"fsq_category_encoded\"] = _fsq_encoder.transform(df[\"location_category_foursquare\"])\n",
    "    df[\"osm_category_encoded\"] = _osm_encoder.transform(df[\"location_category_osm\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed2ad95a-495e-4063-8c5d-295e47e9c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fips_from_coords(lat, lon, retries=3, wait=5):\n",
    "    url = \"https://geo.fcc.gov/api/census/block/find\"\n",
    "    params = {\"latitude\": lat, \"longitude\": lon, \"format\": \"json\"}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=20)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if r.status_code == 502 and i < retries - 1:\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8e932e-ff60-4a5b-9503-e86718a77628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue_estimation(lat, lon):\n",
    "    print(f'Revenue estimation ...')\n",
    "    # print(f'Revenue Est pop density gee {get_population_density_gee(lat, lon, 500)}')\n",
    "    # print(f'Fsq count {get_fsq_count(lat, lon, 500)}')\n",
    "    # print(f'osm poi density {get_osm_poi_density(lat, lon, 500)}')\n",
    "    # print(f'Get median income {get_median_income_by_point(lat, lon, 500)}')\n",
    "    return (get_population_density_gee(lat, lon, 500) * 2 +\n",
    "            get_osm_poi_density(lat, lon, 500) * 100 +\n",
    "            get_fsq_count(lat, lon, 500) * 50 \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a58c175-7044-4091-acb1-808d824d4242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features for location ...\n",
      "Generating circle points with max 50 subcircles\n",
      "low, high 50, 100\n",
      "looper 3\n",
      "looper 2 3\n",
      "haversine condition 36.889138010898556 100\n",
      "haversine condition 56.84741204648442 100\n",
      "looper 2 3\n",
      "haversine condition 25.878023753085042 100\n",
      "haversine condition 50.4030067947202 100\n",
      "looper 2 3\n",
      "haversine condition 28.423571051562558 100\n",
      "haversine condition 51.75612163241232 100\n",
      "Chosen small_radius: 50.00 m, generated 6 subcircles\n",
      "Number of neighborhood points 6\n",
      "Getting population density at (40.47635342220625, -74.22740210887508), radius=50m\n",
      "No population data at radius 50m, expanding search...\n",
      "No population data at radius 100m, expanding search...\n",
      "No population data at radius 200m, expanding search...\n",
      "No population data at radius 400m, expanding search...\n",
      "No population found after expansions. Falling back to nearest town/city center...\n",
      "No population data found, even after fallback.\n",
      "Getting POI density at (40.47635342220625, -74.22740210887508), radius=50m\n",
      "OSM query failed at radius 50m: No matching features. Check query location, tags, and log.\n",
      "OSM query failed at radius 100m: No matching features. Check query location, tags, and log.\n",
      "OSM query failed at radius 200m: No matching features. Check query location, tags, and log.\n",
      "OSM query failed at radius 400m: No matching features. Check query location, tags, and log.\n",
      "No POIs found after expansions. Falling back to nearest town/city center...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m cnt_ = \u001b[32m0\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lat, lon \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# print(f'cnt_ {cnt_}')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     X_df = \u001b[43mbuild_features_for_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Aggregate neighborhood features (mean as example)\u001b[39;00m\n\u001b[32m      7\u001b[39m     agg = X_df.mean(numeric_only=\u001b[38;5;28;01mTrue\u001b[39;00m).to_dict()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mbuild_features_for_location\u001b[39m\u001b[34m(lat, lon, radius_m, cr)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (lat_i, lon_i) \u001b[38;5;129;01min\u001b[39;00m neighborhood_points:\n\u001b[32m      7\u001b[39m     pop = get_population_density_gee(lat_i, lon_i, cr)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     osm_poi = \u001b[43mget_osm_poi_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     fsq_poi = get_fsq_count(lat_i, lon_i, cr)\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# print(f'pop, fsq_poi {pop} {fsq_poi}')\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mget_osm_poi_density\u001b[39m\u001b[34m(lat, lon, radius, max_expand, expand_factor)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Fallback to nearest city/town\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo POIs found after expansions. Falling back to nearest town/city center...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m fallback_coords = \u001b[43mget_nearest_place_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fallback_coords:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_nearest_place_coords\u001b[39m\u001b[34m(lat, lon)\u001b[39m\n\u001b[32m     21\u001b[39m place = addr.get(\u001b[33m\"\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m addr.get(\u001b[33m\"\u001b[39m\u001b[33mtown\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m addr.get(\u001b[33m\"\u001b[39m\u001b[33mvillage\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m place:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     place_loc = \u001b[43mgeolocator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeocode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m place_loc:\n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (place_loc.latitude, place_loc.longitude)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/geopy/geocoders/nominatim.py:297\u001b[39m, in \u001b[36mNominatim.geocode\u001b[39m\u001b[34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[39m\n\u001b[32m    295\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, url)\n\u001b[32m    296\u001b[39m callback = partial(\u001b[38;5;28mself\u001b[39m._parse_json, exactly_one=exactly_one)\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_geocoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/geopy/geocoders/base.py:368\u001b[39m, in \u001b[36mGeocoder._call_geocoder\u001b[39m\u001b[34m(self, url, callback, timeout, is_json, headers)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.adapter.get_text(url, timeout=timeout, headers=req_headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/geopy/adapters.py:472\u001b[39m, in \u001b[36mRequestsAdapter.get_json\u001b[39m\u001b[34m(self, url, timeout, headers)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, *, timeout, headers):\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    474\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resp.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/geopy/adapters.py:482\u001b[39m, in \u001b[36mRequestsAdapter._request\u001b[39m\u001b[34m(self, url, timeout, headers)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, *, timeout, headers):\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m         resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    484\u001b[39m         message = \u001b[38;5;28mstr\u001b[39m(error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/urllib3/connectionpool.py:716\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    713\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_proxy(conn)\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[32m    730\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/urllib3/connectionpool.py:468\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    463\u001b[39m             httplib_response = conn.getresponse()\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m             \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mraise_from\u001b[39m\u001b[34m(value, from_value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/site-packages/urllib3/connectionpool.py:463\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m         httplib_response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m    468\u001b[39m         six.raise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gpu_py311/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "cnt_ = 0\n",
    "for lat, lon in candidates:\n",
    "    # print(f'cnt_ {cnt_}')\n",
    "    X_df = build_features_for_location(lat, lon, radius_m, cr)\n",
    "    # Aggregate neighborhood features (mean as example)\n",
    "    agg = X_df.mean(numeric_only=True).to_dict()\n",
    "    Y = revenue_estimation(lat, lon)\n",
    "    print(f'revenue {Y}')\n",
    "    agg[\"lat\"], agg[\"lon\"], agg[\"revenue\"] = lat, lon,  Y, \n",
    "    # agg[\"lat\"], agg[\"lon\"] = lat, lon\n",
    "    rows.append(agg)\n",
    "    cnt_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48767c3-2560-4016-a2d0-a89a37b30e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44262c-f18a-40e7-bfae-ca5ba094cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f2935-0847-46f0-b63c-f30aa4c1f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065ff67-3143-4820-a7c6-716d7c1eb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vars = encode_location_categories(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298ee9e-262a-4c9c-b499-3cad92ffec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'columns of the df {df_vars.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fac7d-d166-4f3f-a9ac-d0e8252fc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression\n",
    "X = df_vars[[\"population_density\"\n",
    "        , \"osm_poi_density\"\n",
    "        , \"fsq_poi_count\"\n",
    "        , \"median_income\"\n",
    "        , \"fsq_category_encoded\"\n",
    "        , \"osm_category_encoded\"]]\n",
    "y = df_vars[\"revenue\"]\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d146cc-4a05-4e8c-8bfd-95e84b9ef507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846484d8-4959-43b2-b46b-8dec3f90f194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
